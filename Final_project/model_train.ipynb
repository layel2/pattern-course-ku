{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnistmodel_A2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=64,kernel_size=5,stride=1,padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=5,stride=2)\n",
    "        self.dense1 = nn.Linear(in_features=64*12*12,out_features=32)\n",
    "        self.dense2 = nn.Linear(in_features=32,out_features=2)\n",
    "        self.dense3 = nn.Linear(in_features=2,out_features=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.max_pool2d(x,2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x = F.max_pool2d(x,2)\n",
    "        x = F.dropout(x,0.25)\n",
    "        x = x.view(-1,64*12*12)\n",
    "        x = F.sigmoid(self.dense1(x))\n",
    "        x = F.dropout(x,0.5)\n",
    "        x = F.sigmoid(self.dense2(x))\n",
    "        x = F.sigmoid(self.dense3(x))\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]           1,664\n",
      "            Conv2d-2           [-1, 64, 12, 12]         102,464\n",
      "            Linear-3                   [-1, 32]         294,944\n",
      "            Linear-4                    [-1, 2]              66\n",
      "            Linear-5                    [-1, 1]               3\n",
      "================================================================\n",
      "Total params: 399,141\n",
      "Trainable params: 399,141\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.45\n",
      "Params size (MB): 1.52\n",
      "Estimated Total Size (MB): 1.98\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml-lab/anaconda3/envs/ptorch/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "summary(mnistmodel_A2().to(device),(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mnistmodel_A2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getData_pt as getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = getData.normalMnist(data_type='train')\n",
    "test_data = getData.normalMnist(data_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loder_train = train_data.loader\n",
    "loder_test = test_data.loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "n_epochs = 20\n",
    "test_counter = [i*len(loder_train.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=5,verbose=True,factor=0.5)\n",
    "log_interval = 10\n",
    "#cel_loss = nn.CrossEntropyLoss()\n",
    "cel_loss = nn.BCELoss()\n",
    "def train(epoch):\n",
    "    #bbar =  tqdm(total= len(loder_train),desc=\"Batch\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loder_train):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).type(torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = cel_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            '''print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loder_train.dataset),\n",
    "                100. * batch_idx / len(loder_train), loss.item()))'''\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(loder_train.dataset)))\n",
    "            #torch.save(network.state_dict(), './results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), './results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ret=False):\n",
    "    model.eval()\n",
    "    #torch.manual_seed(999)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loder_test:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device).type(torch.float)\n",
    "            #print(data.shape)\n",
    "            output = model(data)\n",
    "            #print(output.shape,target.shape)\n",
    "            test_loss += F.binary_cross_entropy(output, target).item()\n",
    "            #pred = output.data.max(1, keepdim=True)[1]\n",
    "            pred = (output>0.5).type(torch.int)\n",
    "            correct += (pred==target).sum()\n",
    "        test_loss /= len(loder_test.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct, len(loder_test.dataset),100. * correct / len(loder_test.dataset)))\n",
    "        if ret == True:\n",
    "            return (float(correct) / len(loder_test.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 1135/2115 (53.66%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5366430260047281"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(ret=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0726c963414a40918c3d74539aa1ccfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0050, Accuracy: 1135/2115 (53.66%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044, Accuracy: 1135/2115 (53.66%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0040, Accuracy: 1537/2115 (72.67%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036, Accuracy: 2092/2115 (98.91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033, Accuracy: 2108/2115 (99.67%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030, Accuracy: 2112/2115 (99.86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (99.86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022, Accuracy: 2111/2115 (99.81%)\n",
      "\n",
      "Epoch    13: reducing learning rate of group 0 to 2.5000e-04.\n",
      "\n",
      "Test set: Avg. loss: 0.0022, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021, Accuracy: 2114/2115 (99.95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021, Accuracy: 2114/2115 (99.95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020, Accuracy: 2114/2115 (99.95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020, Accuracy: 2113/2115 (99.91%)\n",
      "\n",
      "Epoch    19: reducing learning rate of group 0 to 1.2500e-04.\n",
      "\n",
      "Test set: Avg. loss: 0.0020, Accuracy: 2112/2115 (99.86%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "    train(epoch)\n",
    "    #test()\n",
    "    scheduler.step(test(ret=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0020, Accuracy: 2113/2115 (99.91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk_data = getData.attackMnist(model,atk_loss=nn.BCELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_loader,ret=False):\n",
    "    loder_test = data_loader\n",
    "    model.eval()\n",
    "    #torch.manual_seed(999)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loder_test:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device).type(torch.float)\n",
    "            #print(data.shape)\n",
    "            output = model(data)\n",
    "            #print(output.shape,target.shape)\n",
    "            test_loss += F.binary_cross_entropy(output, target).item()\n",
    "            #pred = output.data.max(1, keepdim=True)[1]\n",
    "            pred = (output>0.5).type(torch.int)\n",
    "            correct += (pred==target).sum()\n",
    "        test_loss /= len(loder_test.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct, len(loder_test.dataset),100. * correct / len(loder_test.dataset)))\n",
    "        if ret == True:\n",
    "            return (float(correct) / len(loder_test.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0035, Accuracy: 1787/2115 (84.49%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(atk_data.loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fdb3c021ed0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atk_data.loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml-lab/anaconda3/envs/ptorch/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type mnistmodel_A2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,'mnist_model/modelA2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
